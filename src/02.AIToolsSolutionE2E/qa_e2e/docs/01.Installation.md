# **Installation**

This guide outlines the steps to set up your environment, install necessary libraries, and structure your project for fine-tuning and inference using Azure ML Service as the backend and ONNX Runtime for samples.

## **1. Set Python Env**
Create and activate a new Conda environment with Python 3.10.12.

```bash


conda create -n slmopsenv python==3.10.12

conda activate slmopsenv


```

## **2. Install Python Library**

Install the required Python libraries from the requirements.txt file.

```bash

pip install -r requirements.txt

```


## **3. Structure**

Your project structure is in the following directories:

```md

|--ğŸ“ QA_E2E
    |-ğŸ“ datasets
    |-ğŸ“ fine-tuning
    |-ğŸ“ inferences
    |-ğŸ“ models-cache
    
```

**ğŸ“ datasets** - Store the data that needs fine-tuning as JSON format files.

**ğŸ“ fine-tuning** - : Store Microsoft Olive settings in `olive-config.json` and save a cache of related steps.

**ğŸ“ inferences** - Store inference models and test results.

**ğŸ“ models-cache** - Save fine-tuned Microsoft Phi-3 mini models








